---
title: "Process and Performance Counter API: EDA"
output: html_notebook
---

**Purpose**: Analyze the process information injunction with the performance counters.  

# Performance Counters

1st, let's review the performance counters, trimming down to the region where the page was accessed.

```{r}
source('../data_munge.R')
file_path <- 'data/exp_bbc_article_20190301_110459/ff_performance_processes_sampled_data.json'
df <- parse_counters_sum(file_path) #, exp_bounds = c(60, 120))
```

```{r}
plot(df$counts)
```


```{r}
get_exp_data <- function(dir_path, exp_bounds = NULL){
  counter_file_path <- file.path(dir_path, 'ff_performance_processes_sampled_data.json')
  ipg_file_path <- list.files(dir_path, pattern='ipg.*_1_.txt', full.names = TRUE)[1]
  df <- get_data(counter_file_path, ipg_file_path, exp_bounds = exp_bounds)
  # df$counter <- c(0, diff(df$counts))
  # df$batt_proc_cum <- df$Cumulative.Processor.Energy_0.mWh.
  return(df)
}

df <- get_exp_data('data/exp_bbc_article_20190301_110459/', exp_bounds = c(70, 120))
```


```{r}
plot(df$counts, df$batt_proc_cum)
```

## Entire Dataset

Loop through the entire dataset, fit a model, compare the slopes

```{r}
lm_eqn <- function(df){
    m <- lm(Cumulative.Processor.Energy_0.mWh. ~ counts, df);
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2, 
         list(a = format(coef(m)[1], digits = 2),
              b = format(coef(m)[2], digits = 2),
             r2 = format(summary(m)$r.squared, digits = 3)))
    as.character(as.expression(eq));
}

fits <- NULL
r2 <- NULL
exp <- NULL
for (dir in dir('data/', full.names = TRUE)){
  df <- get_exp_data(dir, exp_bounds = c(70, 120))
  p <- ggplot(data = df, aes(x = counts, y = Cumulative.Processor.Energy_0.mWh.)) +
    geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
    geom_point() +
    labs(title = dir)
  print(p)
  
  model <- lm(Cumulative.Processor.Energy_0.mWh. ~ counts, df)
  fits <- c(fits, model$coefficients[2])
  r2 <- c(r2, summary(model)$adj.r.squared)
  exp <- c(exp, str_remove(dir, 'data//'))
  
    # geom_text(label = lm_eqn(df), parse = TRUE)
  
names(fits) <- exp
names(r2) <- exp
}
```
```{r}
fits[r2 > 0.90]
```

```{r}
hist(fits[r2 > 0.90], breaks=20)
```

As observed previously, a huge range of dependencies on counters.

Let's look at the coefficient of variation of slopes across website

```{r}
slopes = list()
for (run in exp[r2>0.90]){
  name <- str_split(run, '_2019')[[1]][1]
  slopes[[name]] = c(slopes[[name]], fits[run]) 
}
  

```
```{r}
sapply(slopes, function(x) sd(x)/mean(x))
```

BBC and ESPN have the largest change. 

```{r}
sapply(slopes, mean)
```

# Process Information

## EDA 

Let's perform EDA against `lingscars` as this is the heaviest hitter. 

```{r}
library(jsonlite)
library(stringr)
library(lubridate)

trim_bounds <- function(file_path, exp_bounds){
  measures <- read_json(file_path)
  trimmed <- list()
  timestamp <- hms(str_split(ymd_hms(measures[[1]]$timestamp), ' ')[[1]][2])
  start <- hour(timestamp)*60*60 + minute(timestamp)*60 + second(timestamp)
  i <- 1
  for (measure in measures){
    timestamp <- hms(str_split(ymd_hms(measure$timestamp), ' ')[[1]][2])
    seconds <- hour(timestamp)*60*60 + minute(timestamp)*60 + second(timestamp) - start
    if (seconds > exp_bounds[1] & seconds < exp_bounds[2]){
      trimmed[[i]] <-  measure
      i<-i+1
    }
  }
  return(trimmed)
}

get_seconds <- function(measures){
  timestamp <- hms(str_split(ymd_hms(measures[[1]]$timestamp), ' ')[[1]][2])
  start <- hour(timestamp)*60*60 + minute(timestamp)*60 + second(timestamp)
  seconds <- NULL
  for (measure in measures){
    timestamp <- hms(str_split(ymd_hms(measure$timestamp), ' ')[[1]][2])
    seconds <- c(seconds, hour(timestamp)*60*60 + minute(timestamp)*60 + second(timestamp) - start)
  }
  return(seconds)
}

measures <- read_json('data/exp_lingscars_20190301_104704/ff_performance_processes_sampled_data.json')
# measures <- trim_bounds('data/exp_lingscars_20190301_104704/ff_performance_processes_sampled_data.json', exp_bounds = c(70, 120))
seconds <- get_seconds(measures)
names(measures) <- paste(seconds, 's', sep='')
```

### Parent Process
Looking at the unique values the parent process

```{r}
length(measures)
unique(sapply(measures, function (x) x$processes$process$filename))
```

```{r}
unique(sapply(measures, function (x) x$processes$process$type))
```

```{r}
length(unique(sapply(measures, function (x) x$processes$process$cpuKernel)))
```

```{r}
length(unique(sapply(measures, function (x) x$processes$process$cpuUser)))
```

```{r}
length(unique(sapply(measures, function (x) x$processes$process$pid)))
```
Appears to be a new user and kernel, but same pid for each sample

#### Parent Threads

Number of threads
```{r}
sapply(measures, function (x) length(x$processes$process$threads))
```

### Children Process
Number of children

```{r}
unique(sapply(measures, function (x) length(x$processes$process$children)))
```
Interesting this doesn't change throughout the whole experiment, though the number of parent threads does!

Number of each childs thread
```{r}
get_num_child_threads <- function(measure){
  threads = NULL
  for(child in measure$processes$process$children){
    threads <- c(threads, length(child$threads))
  }
  return(threads)
}

num_child_threads <- sapply(measures, get_num_child_threads)
num_child_threads
```

Massage into long format for `ggplot2`

```{r}
library(tidyr)
library(magrittr)
library(dplyr)
nctt <- num_child_threads %>% 
  data.frame %>% 
  t %>% 
  as.data.frame %>%
  set_colnames(str_replace(names(.), 'V', 'Child_')) %>%
  mutate(seconds = seconds) %>%
  gather('child', 'num_threads', -seconds )

head(nctt)
```

```{r}
library(ggplot2)

ggplot(nctt, aes(x=seconds, y=num_threads, group=child)) +
  geom_line() + 
  geom_point(aes(color=child))
```

Dig into differences in threads between 50 and 75 seconds for Child 3 and Child 4.

```{r}
before <- bind_rows(measures[['50s']]$processes$process$children[3][[1]]$threads)
after <- bind_rows(measures[['75s']]$processes$process$children[3][[1]]$threads)

print(head(before))
setdiff(unique(after$name), unique(before$name))
```

```{r}
before <- bind_rows(measures[['50s']]$processes$process$children[4][[1]]$threads)
after <- bind_rows(measures[['75s']]$processes$process$children[4][[1]]$threads)

print(before)
setdiff(unique(after$name), unique(before$name))


```

```{r}
unique(after$name)
```

Take a look at Slate (which has much less of a demand) to see how they relate
```{r}
measures_low <- read_json('data/exp_slate_20190301_112526/ff_performance_processes_sampled_data.json')
# measures <- trim_bounds('data/exp_lingscars_20190301_104704/ff_performance_processes_sampled_data.json', exp_bounds = c(70, 120))
seconds_low <- get_seconds(measures_low)
names(measures_low) <- paste(seconds_low, 's', sep='')

num_child_threads <- sapply(measures_low, get_num_child_threads)

nctt <- num_child_threads %>% 
  data.frame %>% 
  t %>% 
  as.data.frame %>%
  set_colnames(str_replace(names(.), 'V', 'Child_')) %>%
  mutate(seconds = seconds_low) %>%
  gather('child', 'num_threads', -seconds )


ggplot(nctt, aes(x=seconds, y=num_threads, group=child)) +
  geom_line() + 
  geom_point(aes(color=child))

```

```{r}
before <- bind_rows(measures_low[['50s']]$processes$process$children[3][[1]]$threads)
after <- bind_rows(measures_low[['76s']]$processes$process$children[3][[1]]$threads)
 
setdiff(unique(after$name), unique(before$name))
```


Plot the # of children threads for all experiments

```{r}
plot_num_children <- function(dir_path){
  measures <- read_json(file.path(dir_path, 'ff_performance_processes_sampled_data.json'))
  seconds <- get_seconds(measures)
  names(measures) <- paste(seconds, 's', sep='')
  num_child_threads <- sapply(measures, get_num_child_threads)
  nctt <- num_child_threads %>% 
    data.frame %>% 
    t %>% 
    as.data.frame %>%
    set_colnames(str_replace(names(.), 'V', 'Child_')) %>%
    mutate(seconds = seconds) %>%
    gather('child', 'num_threads', -seconds )
  
  p <- ggplot(nctt, aes(x=seconds, y=num_threads, group=child)) +
    geom_line() + 
    geom_point(aes(color=child)) + 
    labs(title=exp) + 
    theme_bw() +
    guides(color=FALSE)
  print(p)
  return(c(measures=measures, nctt=nctt))
}

results <- list()
for (dir in dir('data/', full.names = TRUE)){
  exp <- basename(dir)
  results[[exp]] <- plot_num_children(dir)
}


```


New York Times and Slate have very similar plots, though very different slopes! Investigate this one further.

Let's look into `residentSetSize` for parent
```{r}
results[['exp_bbc_article_20190301_110459']]
```


**Difference the additional thread names**


**ResidentSetSize for children threads?**

## Comparison
Now let's analyze the process information between the two largest differences in slopes from above.

```{r}
sapply(slopes, mean)
```

Let's examine `lingscars` versus `slate`. 






